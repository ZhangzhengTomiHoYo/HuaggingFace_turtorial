{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f5c6a28-1b08-45cf-be21-d04f984745b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3142e604-f564-4d21-830d-a1655a3789b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9940324425697327},\n",
       " {'label': 'POSITIVE', 'score': 0.9993284940719604}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "#\n",
    "# sentiment 情感\n",
    "# analysis 分析\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\n",
    "        \"I want to fuck u\",\n",
    "        \"I like big dick\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9737d6c8-f416-45dc-9fd1-9a949336723c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b22cd-cfdf-48be-8771-a08967faabb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6df7dc1-00ff-46be-b64f-95f4efe7e356",
   "metadata": {},
   "source": [
    "# 使用 tokenizer/分词器 进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4accbf18-4765-46f1-bf8f-f04ad7d3739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "#\n",
    "# 如你所见 这只是一个string\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "#\n",
    "# 一个分词器的类\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687b3a54-f3d9-4298-8f63-9b2ffa9f5a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  2215,  1037, 13950,  2100,  2450,  2000,  2022,  2026,\n",
      "          2564,   102],\n",
      "        [  101,  1045,  2215,  2000,  6616,   102,     0,     0,     0,     0,\n",
      "             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 原始输入\n",
    "raw_inputs = [\n",
    "    \"I want a busty woman to be my wife\",\n",
    "    \"I want to fuck\",\n",
    "]\n",
    "#\n",
    "# HuggingFace:暂时不用担心填充和截断;我们稍后会解释这些。\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "print(type(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eea89fc9-94b4-419d-a68e-905bec6902b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# 看起来并不是字典类型\n",
    "# 尝试一下最底层算不算是字典\n",
    "inputs[\"input_ids\"]\n",
    "inputs[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29000d0c-1baa-47e5-b89c-820b0be9eb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61fb351-f463-4acc-93db-aa4c059bebdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a30860e-7d9b-4694-b8dc-8cb25c8b597f",
   "metadata": {},
   "source": [
    "# 浏览模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d736046-f880-443d-9f9e-722d0bf183ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6510e6f908ca4b6cad9bba6207d926b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# 没什么 就是模型类\n",
    "from transformers import AutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d415472b-d2ce-4220-a4b1-3d049e6ec895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 小插曲 但很重要的知识\n",
    "def a(**k):\n",
    "    print(type(k))\n",
    "a(**inputs)\n",
    "def b(*k):\n",
    "    print(type(k))\n",
    "b(*inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1cd9207-1cee-4e8e-a6f0-934f1c4e4724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12, 768])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# HuggingFace\n",
    "# NOTE 高维向量 / A high-dimensional vector\n",
    "\n",
    "# Transformer 模块的 vector 输出通常很大。它通常有三个维度：\n",
    "\n",
    "# Batch size：一次处理的序列数（在我们的示例中为 2）。\n",
    "\n",
    "# Sequence length：序列的数字表示长度（在我们的示例中为 16）。\n",
    "\n",
    "# Hidden size / 隐藏大小 ：每个模型输入的向量维度。\n",
    "\n",
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffd343b-c643-4155-967c-7da4e2e2a0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb73c28-c38c-4a19-aacf-71b81217491d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a54dc8d9-eaae-4392-9755-205bc5745ee1",
   "metadata": {},
   "source": [
    "# Model heads: Making sense out of numbers / 模型头：从数字中理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c9377d2-b4a0-4110-88bf-60d69fb0bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Transformer 模型的输出直接发送到模型头进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a79d961-ec61-4a00-bd3a-ae6f05d13f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c207b543-8878-49c5-be8d-ee88d8cea820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93b2879d-5186-4bde-8431-7530e2a0558b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.SequenceClassifierOutput"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b62b841c-5221-422b-9dad-51e79ba13b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.5010,  2.5566],\n",
      "        [ 3.5841, -2.9330]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# HF\n",
    "# 我们的模型预测第一句话为 [-1.5607， 1.6123]，第二句话为 [ 4.1692， -3.3464]。 \n",
    "# 这些不是概率，而是 logits，即模型最后一层输出的原始、未规范化的 分数 / scores \n",
    "print(outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28310662-84b0-46b1-a75a-fbd68e3899af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0063, 0.9937],\n",
      "        [0.9985, 0.0015]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#\n",
    "# 要转换为概率，它们需要经过 SoftMax 层\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)\n",
    "\n",
    "#\n",
    "# （所有 🤗 Transformers 模型都输出 logits，\n",
    "# 因为用于训练的损失函数通常会将最后一个激活函数（如 SoftMax）与实际的损失函数（如交叉熵）融合在一起）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b279eb5-415e-4ced-898d-453578cc66ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
