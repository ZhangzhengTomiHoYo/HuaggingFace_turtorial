{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0871c23-2635-4b9f-b381-10d34607a85f",
   "metadata": {},
   "source": [
    "# Tokenizers 分词器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546fdb74-def2-420e-a91b-de880f48e930",
   "metadata": {},
   "source": [
    "## word-based 基于单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f8e554-e385-445c-8f0c-7ba3b7086ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jim', 'Henson', 'was', 'a', 'puppeteer']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = \"Jim Henson was a puppeteer\".split()\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a5142-9174-41a1-a82f-15d242f760b8",
   "metadata": {},
   "source": [
    "## character-based 基于字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5a7fa-38fb-412a-943f-d263c87e6096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按字符分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8081a0cd-066d-4515-a0f2-c4157c4ebc47",
   "metadata": {},
   "source": [
    "## 子词分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c826f76f-96be-4836-8cdd-84a7afa21d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按语义分 例如，“annoyingly” 可能被认为是一个稀有词，可以分解为“annoying”和“ly”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebdedba-7043-4f75-81df-5c277861805d",
   "metadata": {},
   "source": [
    "## 更多"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5fd79-9182-4acc-a241-10ded7a9f14e",
   "metadata": {},
   "source": [
    "不出所料，还有更多的技术。仅举几例：\n",
    "\n",
    "Byte-level BPE, as used in GPT-2\n",
    "GPT-2 中使用的字节级 BPE\n",
    "\n",
    "WordPiece, as used in BERT\n",
    "WordPiece，在 BERT 中使用\n",
    "\n",
    "SentencePiece or Unigram, as used in several multilingual models\n",
    "SentencePiece 或 Unigram，用于多个多语言模型\n",
    "\n",
    "You should now have sufficient knowledge of how tokenizers work to get started with the API.\n",
    "您现在应该对分词器的工作原理有足够的了解，以开始使用 API。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbfaf43-4d39-40ae-8575-22cbad99e597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375599e-1300-441d-89c7-cea4de0d5d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bbe953c-670e-458f-98de-3c2663cba9b5",
   "metadata": {},
   "source": [
    "## Loading and saving  加载和保存"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7acd0336-e3d5-4bc4-b01e-0abb6ca831de",
   "metadata": {},
   "source": [
    "# 加载和保存分词器与使用模型一样简单。实际上，它基于相同的两种方法：from_pretrained（） 和 save_pretrained（）。 \n",
    "# 这些方法将加载或保存分词器使用的算法（有点像模型的架构 ）及其词汇表（有点像模型的权重 ）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bda7cf2-8595-4160-a1de-c83f38af4355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# HF\n",
    "# 加载使用与 BERT 相同的检查点训练的 BERT 分词器与加载模型的方式相同，只是我们使用 BertTokenizer 类：\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e513ec2e-939f-4dae-87ad-7d435c074d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 还有一个 auto的\n",
    "#\n",
    "# HF\n",
    "# 与 AutoModel 类似，AutoTokenizer 类将根据检查点名称在库中获取适当的 tokenizer 类，并且可以直接与任何检查点一起使用：\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6c7683a-e37f-476d-9bd3-d01ab2896ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7993, 170, 13809, 23763, 2443, 1110, 3014, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用\n",
    "tokenizer(\"Using a Transformer network is simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df2ad165-794b-4e55-8d91-a4f58a45b133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('directory_on_my_computer\\\\tokenizer_config.json',\n",
       " 'directory_on_my_computer\\\\special_tokens_map.json',\n",
       " 'directory_on_my_computer\\\\vocab.txt',\n",
       " 'directory_on_my_computer\\\\added_tokens.json',\n",
       " 'directory_on_my_computer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# HF\n",
    "# 保存 tokenizer 与保存模型相同：\n",
    "tokenizer.save_pretrained(\"directory_on_my_computer\")\n",
    "#\n",
    "# 好复杂的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abfecba-0059-45a0-b7b8-a1c316039902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef14d1-c5e3-4c16-9661-f4d21c02a477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c535046-59e6-40e4-9886-ad3218e36d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8355ad-f81c-4f57-9c69-1c1499acf2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9363835-478b-44d8-bb6d-8458762ce280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91df1180-7714-4338-99f0-4e72092b981e",
   "metadata": {},
   "source": [
    "# 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f97776e-79d7-4b8d-bd4e-f8c5a4147149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# HF\n",
    "# 将文本转换为数字称为编码 。编码分两个步骤完成：\n",
    "#  1. 分词化，\n",
    "#  2. 然后转换为输入 ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a03734-8012-492d-8d7b-76a87c8625da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正如我们所看到的，第一步是将文本拆分为单词（或单词的一部分、标点符号等），通常称为标记 / usually called tokens ！！！！。\n",
    "# token ！！！！！！\n",
    "# 有多个规则可以控制该过程，\n",
    "# 这就是为什么我们需要使用模型的名称实例化分词器，\n",
    "# 以确保我们使用与模型预训练时使用的相同规则。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efee5663-f285-4597-9040-5f847efbb6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二步是将这些标记转换为数字，这样我们就可以从中构建一个张量并将它们提供给模型。\n",
    "# 为此，分词器有一个词汇表 ，\n",
    "# 这是我们使用 from_pretrained（） 方法实例化它时下载的部分。\n",
    "# 同样，我们需要使用模型预训练时使用的相同词汇。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1329061-e6a9-4646-a6fa-94240c386cff",
   "metadata": {},
   "source": [
    "## Tokenization  分词化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d4598a2-a805-403a-9b2d-72cb065bcbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# HF\n",
    "# 分词化过程由 tokenizer 的 tokenize（） 方法完成：\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "sequence = \"Using a Transformer network is simple\"\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "# 此方法的输出是字符串或 tokens 的列表：\n",
    "# 这个分词器是一个子词分词器：\n",
    "# 它拆分单词，直到获得可以用其词汇表表示的词元。\n",
    "# transformer 就是这种情况，它被分成两个标记：transform 和 ##er。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f408e39-ac12-4386-b8c0-fb3edeaf3d24",
   "metadata": {},
   "source": [
    "## 从令牌/ tokens 到输入 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4022b6c-03fa-46f7-b3c5-fce278e62303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7993, 170, 13809, 23763, 2443, 1110, 3014]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# 到 输入 ID 的转换由 convert_tokens_to_ids（） 分词器方法处理：\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f8b081-d009-4a85-abcb-052aae994884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb896c2-dfb2-42bb-92ed-3335c8ffb100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff7c2e-f414-43c1-a37d-bb528725c58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d48313-4005-497f-8760-67945c798d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd010f24-654f-4419-a91e-c4e9b31ba047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc2b955c-ff53-4274-8f1c-3eff6e06d9a8",
   "metadata": {},
   "source": [
    "\n",
    "#  Decoding  译码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba30528-828d-4125-ab2e-f1873855fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# HF\n",
    "# 从词汇索引中，我们想要得到一个字符串。这可以通过 decode（） 方法完成，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a835a52b-5694-4d6b-997f-3367085673af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a transformer network is simple\n"
     ]
    }
   ],
   "source": [
    "decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\n",
    "print(decoded_string)\n",
    "# 请注意，decode 方法不仅将索引转换回标记，\n",
    "# 而且还将属于相同单词的标记组合在一起，以生成可读的句子。\n",
    "# \n",
    "# 当我们使用预测新文本的模型（从提示生成的文本，或者用于翻译或摘要等序列到序列问题）时，\n",
    "# 这种行为将非常有用。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "134ebe27-b300-41a9-9353-c1728f3f7202",
   "metadata": {},
   "source": [
    "到目前为止，您应该了解分词器可以处理的原子作：分词化、转换为 ID 以及将 ID 转换回字符串。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6eb56de-3f4e-492c-b437-3628935679b0",
   "metadata": {},
   "source": [
    "然而，我们只是刮擦了冰山一角。在下一节中，我们将探讨我们的方法的极限，并看看如何克服它们。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
