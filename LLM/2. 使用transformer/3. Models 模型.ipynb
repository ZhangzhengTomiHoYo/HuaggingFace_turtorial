{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b0b96af-86fd-4474-929e-65a9e0639e6f",
   "metadata": {},
   "source": [
    "# 创建Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a020e8fb-b64f-4e0e-b640-91a6b8473d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6247e184-4f76-4c8f-9bcf-cca35696e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78148684-5bcc-49d3-86d4-e5cf61271bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a57be4-8d24-4bc7-ac62-51376fd36063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(config)\n",
    "#\n",
    "# HF\n",
    "# hidden_size 属性定义 hidden_states 向量的大小，\n",
    "# num_hidden_layers 定义 Transformer 模型具有的层数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076b0eb-5894-4a01-b9fc-30744742f5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489719e8-240b-4612-b9a4-ac986c9baf27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76f46aab-5f44-4eb5-9c07-866d8362b543",
   "metadata": {},
   "source": [
    "## 不同的加载方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60645ea1-1d6b-4522-9114-d220a6eeccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 代码和上面一样\n",
    "# 想要表达的是 这样加载的模型 权重会随机初始化\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "config = BertConfig()\n",
    "model = BertModel(config)\n",
    "\n",
    "# Model is randomly initialized!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1951a86-fe78-46aa-83db-9e765e369b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8aaa449b2c418caf266a9d747b4a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\HF\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\admin\\.cache\\huggingface\\hub\\models--bert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5d99da812f42fcaa81bab3dae9e299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# 当然 我们需要的是预训练的模型\n",
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "#\n",
    "# HF\n",
    "# 在上面的代码示例中，我们没有使用 BertConfig，而是通过 bert-base-cased 标识符加载了预训练模型。\n",
    "# 这是一个由 BERT 的作者自己训练的模型检查点;\n",
    "# 您可以在其 型号卡/model card 中找到有关它的更多详细信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5692924-1bf2-4228-8d71-da6d0d1928e9",
   "metadata": {},
   "source": [
    "## 保存方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b68599-eb4d-4cd4-b8d5-21b26485879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"directory_on_my_computer\")\n",
    "#\n",
    "# 保存了两个文件 config.json pytorch_model.bin\n",
    "# .bin 等于 .safetensors\n",
    "# \n",
    "# pytorch_model.bin 文件称为  状态字典 / state dictionary \n",
    "# 它包含模型的所有权重。这两个文件齐头并进;该配置对于了解模型的架构是必需的，而模型权重是模型的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94d62d-71b8-412c-b784-83df0cfbc075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c4b153-3f54-44b1-bbed-ddedbfbe93be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638ca96-663e-4910-834b-14de108e779e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff178667-ada6-40f7-8e40-be272f858961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95a706db-6f96-4185-a1a6-25aed4dba113",
   "metadata": {},
   "source": [
    "# 使用 Transformer 模型进行推理\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cabcc0-5529-426e-a929-b99fd3d8fcf3",
   "metadata": {},
   "source": [
    "很好 学习了加载和保存 接下来要推理了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41e47ced-0979-4782-99ca-06be5e5a6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2feec18e-19df-4818-9de8-60bffb0da5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = [\n",
    "    [101, 7592, 999, 102],\n",
    "    [101, 4658, 1012, 102],\n",
    "    [101, 3835, 999, 102],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ca59a82-5d88-4a56-9e91-aa910a4a789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model_inputs = torch.tensor(encoded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d661c97b-d839-4f1b-b492-207f82864629",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ded2e7cd-b44b-4752-b77f-f94515920c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 4.4496e-01,  4.8276e-01,  2.7797e-01,  ..., -5.4032e-02,\n",
       "           3.9393e-01, -9.4770e-02],\n",
       "         [ 2.4943e-01, -4.4093e-01,  8.1772e-01,  ..., -3.1917e-01,\n",
       "           2.2992e-01, -4.1172e-02],\n",
       "         [ 1.3668e-01,  2.2518e-01,  1.4502e-01,  ..., -4.6914e-02,\n",
       "           2.8224e-01,  7.5566e-02],\n",
       "         [ 1.1789e+00,  1.6739e-01, -1.8187e-01,  ...,  2.4671e-01,\n",
       "           1.0441e+00, -6.1972e-03]],\n",
       "\n",
       "        [[ 3.6436e-01,  3.2464e-02,  2.0258e-01,  ...,  6.0111e-02,\n",
       "           3.2451e-01, -2.0996e-02],\n",
       "         [ 7.1866e-01, -4.8725e-01,  5.1740e-01,  ..., -4.4012e-01,\n",
       "           1.4553e-01, -3.7545e-02],\n",
       "         [ 3.3223e-01, -2.3271e-01,  9.4876e-02,  ..., -2.5268e-01,\n",
       "           3.2172e-01,  8.1122e-04],\n",
       "         [ 1.2523e+00,  3.5754e-01, -5.1320e-02,  ..., -3.7840e-01,\n",
       "           1.0526e+00, -5.6255e-01]],\n",
       "\n",
       "        [[ 2.4042e-01,  1.4718e-01,  1.2110e-01,  ...,  7.6062e-02,\n",
       "           3.3564e-01,  2.8262e-01],\n",
       "         [ 6.5701e-01, -3.2787e-01,  2.4968e-01,  ..., -2.5920e-01,\n",
       "           2.0175e-01,  3.3275e-01],\n",
       "         [ 2.0160e-01,  1.5783e-01,  9.8969e-03,  ..., -3.8850e-01,\n",
       "           4.1307e-01,  3.9732e-01],\n",
       "         [ 1.0175e+00,  6.4387e-01, -7.8147e-01,  ..., -4.2109e-01,\n",
       "           1.0925e+00, -4.8455e-02]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.6856,  0.5262,  1.0000,  ...,  1.0000, -0.6112,  0.9971],\n",
       "        [-0.6055,  0.4997,  0.9998,  ...,  0.9999, -0.6753,  0.9769],\n",
       "        [-0.7702,  0.5447,  0.9999,  ...,  1.0000, -0.4655,  0.9894]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a66a05-0b32-4f0e-8b4e-ab25b730d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 教学写的不好 戛然而止了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
